---
title: "Random Forest Disturbance Classification"
output:
  html_document:
    theme: default
    highlight: pygments
    toc: true
    toc_depth: 4
    toc_float: true
editor_options:
  chunk_output_type: console
---
author: Dan Wexler\
date: `r Sys.Date()`
```{r setup,include=FALSE}
# file settings
knitr::opts_chunk$set(include=TRUE,echo=TRUE)
```

#### Setup
```{r more setup,message=FALSE,warning=FALSE}
# loads data and libraries
setwd("C:/Users/dwexler/Desktop/R/nps-repo/rf")
x <- read.csv("rf_data.csv")
y <- read.csv("rf_labels.csv")
suppressWarnings({library(randomForest)})
suppressWarnings({library(knitr)})
suppressWarnings({library(ggplot2)})
suppressWarnings({library(tidyr)})
```

#### Cleaning Data
```{r cleaning data}
# removes patches without a labeled change type
x <- x[y$ChangeType!="",]
y <- y[y$ChangeType!="",]
# filters by variable and converts x data to numeric
variables <- c("durMn","durSd","idxMagMn","idxMagSd","tcbMagMn","tcbMagSd",
               "tcgMagMn","tcgMagSd","tcwMagMn","tcwMagSd","tcbPreMn",
               "tcbPreSd","tcgPreMn","tcgPreSd","tcwPreMn","tcwPreSd",
               "tcbPstMn","tcbPstSd","tcgPstMn","tcgPstSd","tcwPstMn",
               "tcwPstSd","area","perim","shape_1","tcbPst01Mn","tcbPst01Sd",
               "tcbPst03Mn","tcbPst03Sd","tcbPst07Mn","tcbPst07Sd",
               "tcbPst15Mn","tcbPst15Sd","tcgPst01Mn","tcgPst01Sd",
               "tcgPst03Mn","tcgPst03Sd","tcgPst07Mn","tcgPst07Sd",
               "tcgPst15Mn","tcgPst15Sd","tcwPst01Mn","tcwPst01Sd",
               "tcwPst03Mn","tcwPst03Sd","tcwPst07Mn","tcwPst07Sd",
               "tcwPst15Mn","tcwPst15Sd")
x <- data.frame(sapply(x[,variables],as.numeric))
y <- data.frame(y[c("ChangeType")])
# filters by disturbance type 
disturbances <- c("Avalanche","Inter-annual Variability","Clearing",
                  "Mass Movement","Progressive Defoliation","Riparian",
                  "Fire","Post Fire Defoliation","Tree Toppling",
                  "Development","Post Clearing","Post Tree Toppling","Water")
kable(table(y),align="l",caption="Frequency distribution of all data")
y[y[,1]=="Post Fire Defoliation",] <- "Fire"
y[y[,1]=="Post Tree Toppling",] <- "Tree Toppling"
y[y[,1]=="Post Clearing",] <- "Clearing"
# EDIT 'disturbances' TO CHANGE DISTURBANCES INCLUDED IN MODEL
dist_subset <- c(1,2,3,4,5,6,7,9)
disturbances <- disturbances[dist_subset]
dists <- length(disturbances)
x <- x[y[,1]%in%disturbances,]
y <- y[y[,1]%in%disturbances,,drop=FALSE]
```

#### Train-Test Split
```{r train-test split}
# creates a training and testing set
x_train <- data.frame(matrix(0,0,ncol(x)))
y_train <- data.frame(matrix("",0,1))
x_test <- data.frame(matrix(0,0,ncol(x)))
y_test <- data.frame(matrix("",0,1))
# EDIT 'split' TO CHANGE THE TRAINING SPLIT
split <- 0.75
for (disturbance in disturbances) {
  x_subset <- x[y[,1]==disturbance,]
  y_subset <- y[y[,1]==disturbance,,drop=FALSE]
  num_rows <- nrow(x_subset)
  index_subset <- sample.int(num_rows,num_rows*split)
  x_train <- rbind(x_train,x_subset[index_subset,])
  y_train <- rbind(y_train,y_subset[index_subset,,drop=FALSE])
  x_test <- rbind(x_test,x_subset[-index_subset,])
  y_test <- rbind(y_test,y_subset[-index_subset,,drop=FALSE])
}
y_train <- factor(sapply(y_train,as.factor))
y_test <- factor(sapply(y_test,as.factor))
```

#### Random Forest Training
```{r random forest iterations}
# constructs vector to balance the training data
sample <- table(y_train)
sample <- replace(sample,sample>100,100)
# EDIT 'reps' TO CHANGE THE NUMBER OF TREES IN EACH RANDOM FOREST
reps <- 50
# runs random forest and extracts most important variables
forest <- randomForest(x=x_train,y=y_train,importance=TRUE,ntree=reps,sampsize=sample)
gini <- forest$importance[,"MeanDecreaseGini"]
# runs random forest using different combinations of variables
# EDIT 'percentages' TO CHANGE PERCENTILE CUTOFFS FOR VARIABLES
percentages <- seq(0,0.9,0.1)
results <- data.frame(matrix(0,length(percentages),7))
colnames(results) <- c("numPredictors","oobError","avgClassError","maxError",
                       "1stPredictor","2ndPredictor","3rdPredictor")
predictions <- data.frame(matrix(0,length(percentages),dists))
colnames(predictions) <- sort(disturbances)
min_class_error <- 99999
best_variables <- NULL
for (i in 1:length(percentages)) {
  x_subset <- x_train[,gini>quantile(gini,probs=percentages[i])]
  forest_subset <- randomForest(x=x_subset,y=y_train,importance=TRUE,ntree=reps,sampsize=sample)
  results[i,1] <- ncol(x_subset)
  results[i,2] <- round(forest_subset$err.rate[reps,"OOB"]*100,2)
  avg_class_error <- round(mean(forest_subset$confusion[,"class.error"])*100,2)
  # stores predictor variables used during the lowest error run
  results[i,3] <- avg_class_error
  if (avg_class_error < min_class_error) {
    min_class_error <- avg_class_error
    best_variables <- colnames(x_subset)
  }
  results[i,4] <- round(max(forest_subset$confusion[,"class.error"])*100,2)
  gini_subset <- data.frame(forest_subset$importance[,"MeanDecreaseGini"])
  colnames(gini_subset) <- c("gini")
  sorted_gini <- rownames(gini_subset)[order(gini_subset$gini,decreasing=TRUE)]
  results[i,c(5,6,7)] <- sorted_gini[c(1,2,3)]
  predictions[i,] <- round(forest_subset$confusion[,"class.error"]*100,2)
}
# displays results
sample_print <- as.data.frame(sample)
colnames(sample_print) <- c("ChangeType","Freq")
kable(sample_print,align="l",caption="Frequency distribution of disturbances used to train model")
kable(results,align="l",row.names=TRUE,caption="Error rates and top predictors from all runs")
kable(predictions,align="l",row.names=TRUE,caption="Disturbance specific errors from all runs")
```

#### Random Forest Testing
```{r random forest testing}
# runs random forest with most predictive variables and displays results
x_train_subset <- x_train[,best_variables]
x_test_subset <- x_test[,best_variables]
best_forest <- randomForest(x=x_train_subset,y=y_train,xtest=x_test_subset,
                            ytest=y_test,importance=TRUE,ntree=reps,sampsize=sample)
# calculates statistics for random forest run
confusion_train <- best_forest$confusion
confusion_train[,"class.error"] <- round(confusion_train[,"class.error"]*100,2)
colnames(confusion_train)[length(colnames(confusion_train))] <- "Error"
oob_error <- round(best_forest$err.rate[reps,"OOB"]*100,2)
class_error_train <- round(mean(best_forest$confusion[,"class.error"])*100,2)
confusion_test <- best_forest$test$confusion
confusion_test[,"class.error"] <- round(confusion_test[,"class.error"]*100,2)
colnames(confusion_test)[length(colnames(confusion_test))] <- "Error"
class_error_test <- round(mean(best_forest$test$confusion[,"class.error"])*100,2)
avalanche_test <- confusion_test["Avalanche","Error"]
toppling_test <- confusion_test["Tree Toppling","Error"]
# displays results
kable(confusion_train,align="l",caption=paste
      ("Confusion matrix for best training run with ",
        ncol(x_train_subset)," variables (avg class error: ",
        class_error_train,", oob_error: ",oob_error,")",sep=""))
kable(confusion_test,align="l",caption=paste
      ("Confusion matrix for test set with ",ncol(x_train_subset),
        " variables (avg class error: ",class_error_test,")",sep=""))
```

#### Plotting Test Results
```{r plotting test results,fig.align='center',warning=FALSE}
# gets the percent of trees that voted for each correct classification
votes <- best_forest$test$votes
vote_percents <- data.frame()
for (i in 1:nrow(votes)) {
  row <- votes[i,]
  label <- colnames(votes)[which.max(row)]
  if (label==y_test[i]) {
    row_num <- nrow(vote_percents)+1
    vote_percents[row_num,1] <- max(row)
    vote_percents[row_num,2] <- label
  }
}
# divides these winning classifications into bins based on confidence
thresholds_graph <- data.frame(matrix(0,5,dists+1))
thresholds_graph[,dists+1] <- c("80-100%","60-80%","40-60%","20-40%","0-20%")
for (i in 1:dists) {
  vote_subset <- vote_percents[vote_percents[,2]==disturbances[i],1]
  den <- length(vote_subset)
  thresholds_graph[1,i] <- (length(vote_subset[(vote_subset>=.8&vote_subset<=1)])/den)*100
  thresholds_graph[2,i] <- (length(vote_subset[(vote_subset>=.6&vote_subset<.8)])/den)*100
  thresholds_graph[3,i] <- (length(vote_subset[(vote_subset>=.4&vote_subset<.6)])/den)*100
  thresholds_graph[4,i] <- (length(vote_subset[(vote_subset>=.2&vote_subset<.4)])/den)*100
  thresholds_graph[5,i] <- (length(vote_subset[(vote_subset>=0&vote_subset<.2)])/den)*100
}
# plots the results
dist_labels <- c("Avalanche","IntAnnVar","Clearing","MassMov","ProgDef",
                 "Riparian","Fire","PostFireDef","TreeTopp","Devel",
                 "PostClear","PostTreeTopp","Water")
labels_subset <- dist_labels[dist_subset]
colnames(thresholds_graph) <- append(labels_subset,"Confidence")
thresholds_graph <- pivot_longer(data=thresholds_graph,cols=labels_subset,
                                 names_to="Disturbance",values_to="Percent")
ggplot(data=thresholds_graph,aes(x=Disturbance,y=Percent,fill=Confidence))+
  geom_bar(stat="identity",color="black",width=0.9,position=position_stack(reverse=TRUE))+
  labs(y="% of Disturbances",title="RF Correct Classification Confidence Levels")+
  guides(fill=guide_legend(reverse=TRUE))+theme(plot.title=element_text(hjust=0.5))
```

```{r}
threshold <- -1
thresholded <- data.frame(matrix(0,1,dists))
y_test <- as.data.frame(y_test)
for (i in 1:dists) {
  vote_subset <- votes[y_test==disturbances[i],]
  y_test_subset <- y_test[y_test==disturbances[i],,drop=FALSE]
  num <- 0
  den <- 0
  for (j in 1:nrow(vote_subset)) {
    row <- vote_subset[j,]
    if (max(row) > threshold) {
      den <- den+1
      # thresholded[2,i] <- thresholded[2,i]+1
      if (colnames(votes)[which.max(row)]==y_test_subset[j,1]) {
        num <- num+1
        # thresholded[1,i] <- thresholded[1,i]+1
      }
    }
  }
  thresholded[1,i] <- round((1-(num/den))*100,2)
}
colnames(thresholded) <- labels_subset
print(thresholded)
```

#### Training New Forest
```{r retraining}
# subsets data to only include avalanche and tree toppling events
dists_v2 <- c("Avalanche","Tree Toppling")
y_train <- as.data.frame(y_train)
y_test <- as.data.frame(y_test)
x_train_v2 <- x_train[y_train[,1]%in%dists_v2,]
y_train_v2 <- y_train[y_train[,1]%in%dists_v2,,drop=FALSE]
x_test_v2 <- x_test[y_test[,1]%in%dists_v2,]
y_test_v2 <- y_test[y_test[,1]%in%dists_v2,,drop=FALSE]
y_train <- factor(sapply(y_train,as.factor))
y_test <- factor(sapply(y_test,as.factor))
y_train_v2 <- factor(sapply(y_train_v2,as.factor))
y_test_v2 <- factor(sapply(y_test_v2,as.factor))
```

```{r new rf iterations}
# runs random forest and extracts most important variables
forest <- randomForest(x=x_train_v2,y=y_train_v2,importance=TRUE,ntree=reps)
gini <- forest$importance[,"MeanDecreaseGini"]
# runs random forest using different combinations of variables
min_class_error <- 99999
best_variables <- NULL
for (i in 1:length(percentages)) {
  x_subset <- x_train_v2[,gini>quantile(gini,probs=percentages[i])]
  forest_subset <- randomForest(x=x_subset,y=y_train_v2,importance=TRUE,ntree=reps)
  # stores predictor variables used during the lowest error run
  if (avg_class_error < min_class_error) {
    min_class_error <- avg_class_error
    best_variables <- colnames(x_subset)
  }
}
```

```{r new rf testing}
# runs random forest with most predictive variables and displays results
x_train_subset_v2 <- x_train_v2[,best_variables]
x_test_subset_v2 <- x_test_v2[,best_variables]
best_forest_v2 <- randomForest(x=x_train_subset_v2,y=y_train_v2,xtest=x_test_subset_v2,
                            ytest=y_test_v2,importance=TRUE,ntree=reps)
# calculates statistics for random forest run
confusion_train <- best_forest_v2$confusion
confusion_train[,"class.error"] <- round(confusion_train[,"class.error"]*100,2)
colnames(confusion_train)[length(colnames(confusion_train))] <- "Error"
oob_error <- round(best_forest_v2$err.rate[reps,"OOB"]*100,2)
class_error_train <- round(mean(best_forest_v2$confusion[,"class.error"])*100,2)
confusion_test <- best_forest_v2$test$confusion
confusion_test[,"class.error"] <- round(confusion_test[,"class.error"]*100,2)
colnames(confusion_test)[length(colnames(confusion_test))] <- "Error"
class_error_test <- round(mean(best_forest_v2$test$confusion[,"class.error"])*100,2)
# displays results
kable(confusion_train,align="l",caption=paste
      ("Confusion matrix for best training run with ",
        ncol(x_train_subset_v2)," variables (avg class error: ",
        class_error_train,", oob_error: ",oob_error,")",sep=""))
kable(confusion_test,align="l",caption=paste
      ("Confusion matrix for test set with ",ncol(x_train_subset_v2),
        " variables (avg class error: ",class_error_test,")",sep=""))
avalanche_test_v2 <- confusion_test["Avalanche","Error"]
toppling_test_v2 <- confusion_test["Tree Toppling","Error"]
v2_results <- data.frame(Avalanche=c(avalanche_test,avalanche_test_v2),
                         TreeTopp=c(toppling_test,toppling_test_v2))
rownames(v2_results) <- c("Initial Testing Error","Retrained Testing Error")
kable(v2_results,align="l",caption="Initial and retrained testing errors")
```

