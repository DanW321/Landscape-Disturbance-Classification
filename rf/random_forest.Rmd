---
title: "Random Forest Disturbance Classification"
output:
  html_document:
    theme: darkly
    highlight: kate
    toc: true
    toc_depth: 4
    toc_float: true
editor_options:
  chunk_output_type: console
---
author: Dan Wexler\
date: `r Sys.Date()`
```{r setup,include=FALSE}
# file settings
knitr::opts_chunk$set(include=TRUE,echo=TRUE)
```
#### Setup
```{r more setup,message=FALSE}
# loads data and libraries
setwd("C:/Users/dwexler/Desktop/R/nps-repo/rf")
x <- read.csv("rf_data.csv")
y <- read.csv("rf_labels.csv")
suppressWarnings({library(randomForest)})
suppressWarnings({library(knitr)})
```
#### Cleaning Data
```{r cleaning data}
# removes patches without a labeled change type
x <- x[y$ChangeType!="",]
y <- y[y$ChangeType!="",]
# filters by variable and converts x data to numeric
variables <- c("durMn","durSd","idxMagMn","idxMagSd","tcbMagMn","tcbMagSd",
               "tcgMagMn","tcgMagSd","tcwMagMn","tcwMagSd","tcbPreMn",
               "tcbPreSd","tcgPreMn","tcgPreSd","tcwPreMn","tcwPreSd",
               "tcbPstMn","tcbPstSd","tcgPstMn","tcgPstSd","tcwPstMn",
               "tcwPstSd","area","perim","shape_1","tcbPst01Mn","tcbPst01Sd",
               "tcbPst03Mn","tcbPst03Sd","tcbPst07Mn","tcbPst07Sd",
               "tcbPst15Mn","tcbPst15Sd","tcgPst01Mn","tcgPst01Sd",
               "tcgPst03Mn","tcgPst03Sd","tcgPst07Mn","tcgPst07Sd",
               "tcgPst15Mn","tcgPst15Sd","tcwPst01Mn","tcwPst01Sd",
               "tcwPst03Mn","tcwPst03Sd","tcwPst07Mn","tcwPst07Sd",
               "tcwPst15Mn","tcwPst15Sd")
x <- data.frame(sapply(x[,variables],as.numeric))
y <- data.frame(y[c("ChangeType")])
# filters by disturbance type 
disturbances <- c("Avalanche","Inter-annual Variability","Clearing",
                  "Mass Movement","Progressive Defoliation","Riparian",
                  "Fire","Post Fire Defoliation","Tree Toppling",
                  "Development","Post Clearing","Post Tree Toppling","Water")
# EDIT 'disturbances' TO CHANGE DISTURBANCES INCLUDED IN MODEL
disturbances <- disturbances[c(1,2,3,4,5,6,7,8,9)]
x <- x[y[,1]%in%disturbances,]
y <- y[y[,1]%in%disturbances,,drop=FALSE]
```
#### Train-Test Split
```{r train-test split}
# creates a training and testing set
x_train <- data.frame(matrix(0,0,ncol(x)))
y_train <- data.frame(matrix("",0,1))
x_test <- data.frame(matrix(0,0,ncol(x)))
y_test <- data.frame(matrix("",0,1))
# EDIT 'split' TO CHANGE THE TRAINING TESTING SPLIT
split <- 0.75
for (disturbance in disturbances) {
  x_subset <- x[y[,1]==disturbance,]
  y_subset <- y[y[,1]==disturbance,,drop=FALSE]
  num_rows <- nrow(x_subset)
  set.seed(1)
  index_subset <- sample.int(num_rows,num_rows*split)
  x_train <- rbind(x_train,x_subset[index_subset,])
  y_train <- rbind(y_train,y_subset[index_subset,,drop=FALSE])
  x_test <- rbind(x_test,x_subset[-index_subset,])
  y_test <- rbind(y_test,y_subset[-index_subset,,drop=FALSE])
}
y_train <- factor(sapply(y_train,as.factor))
y_test <- factor(sapply(y_test,as.factor))
```
#### Random Forest Training
```{r random forest iterations}
# constructs vector to balance the training data
sample <- table(y_train)
sample <- replace(sample,sample>100,100)
# EDIT 'reps' TO CHANGE THE NUMBER OF TREES IN EACH RANDOM FOREST
reps <- 50
# runs random forest and extracts most important variables
forest <- randomForest(x=x_train,y=y_train,importance=TRUE,ntree=reps,sampsize=sample)
gini <- forest$importance[,"MeanDecreaseGini"]
# runs random forest using different combinations of variables
# EDIT 'percentages' TO CHANGE PERCENTILE CUTOFFS FOR VARIABLES
percentages <- seq(0,0.9,0.1)
results <- data.frame(matrix(0,length(percentages),9))
colnames(results) <- c("numPredictors","oobError","avgClassError",
                       "maxError","1stPredictor","2ndPredictor",
                       "3rdPredictor","4thPredictor","5thPredictor")
predictions <- data.frame(matrix(0,length(percentages),length(disturbances)))
colnames(predictions) <- sort(disturbances)
min_class_error <- 99999
best_variables <- NULL
for (i in 1:length(percentages)) {
  x_subset <- x_train[,gini>quantile(gini,probs=percentages[i])]
  forest_subset <- randomForest(x=x_subset,y=y_train,importance=TRUE,ntree=reps,sampsize=sample)
  results[i,1] <- ncol(x_subset)
  results[i,2] <- round(forest_subset$err.rate[reps,"OOB"]*100,2)
  avg_class_error <- round(mean(forest_subset$confusion[,"class.error"])*100,2)
  # stores predictor variables used during the lowest error run
  results[i,3] <- avg_class_error
  if (avg_class_error < min_class_error) {
    min_class_error <- avg_class_error
    best_variables <- colnames(x_subset)
  }
  results[i,4] <- round(max(forest_subset$confusion[,"class.error"])*100,2)
  gini_subset <- data.frame(forest_subset$importance[,"MeanDecreaseGini"])
  colnames(gini_subset) <- c("gini")
  sorted_gini <- rownames(gini_subset)[order(gini_subset$gini,decreasing=TRUE)]
  results[i,c(5,6,7,8,9)] <- sorted_gini[c(1,2,3,4,5)]
  predictions[i,] <- round(forest_subset$confusion[,"class.error"]*100,2)
}
# displays results
sample_print <- as.data.frame(sample)
colnames(sample_print) <- c("disturbance","frequency")
kable(sample_print,align="l",caption="frequency distribution of disturbances used to train model")
kable(results,align="l",row.names=TRUE,caption="error rates and top predictors from all runs")
kable(predictions,align="l",row.names=TRUE,caption="disturbance specific errors from all runs")
```
#### Random Forest Testing
```{r random forest testing}
# runs random forest with most predictive variables and displays results
x_train_subset <- x_train[,best_variables]
x_test_subset <- x_test[,best_variables]
best_forest <- randomForest(x=x_train_subset,y=y_train,xtest=x_test_subset,
                            ytest=y_test,importance=TRUE,ntree=reps,sampsize=sample)
# calculates statistics for random forest run
confusion_train <- best_forest$confusion
confusion_train[,"class.error"] <- round(confusion_train[,"class.error"]*100,2)
colnames(confusion_train)[length(colnames(confusion_train))] <- "Error"
oob_error <- round(best_forest$err.rate[reps,"OOB"]*100,2)
class_error_train <- round(mean(best_forest$confusion[,"class.error"])*100,2)
confusion_test <- best_forest$test$confusion
confusion_test[,"class.error"] <- round(confusion_test[,"class.error"]*100,2)
colnames(confusion_test)[length(colnames(confusion_test))] <- "Error"
class_error_test <- round(mean(best_forest$test$confusion[,"class.error"])*100,2)
# displays results
kable(confusion_train,align="l",caption=paste
      ("confusion matrix for best training run with ",
        ncol(x_train_subset)," variables (avg class error: ",
        class_error_train,", oob_error: ",oob_error,")",sep=""))
kable(confusion_test,align="l",caption=paste
      ("confusion matrix for test set with ",ncol(x_train_subset),
        " variables (avg class error: ",class_error_test,")",sep=""))
```
