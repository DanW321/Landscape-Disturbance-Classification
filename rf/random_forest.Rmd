---
title: "Random Forest Disturbance Classification"
output:
  html_document:
    theme: default
    highlight: pygments
    toc: true
    toc_depth: 4
    toc_float: true
editor_options:
  chunk_output_type: console
---
author: Dan Wexler\
date: `r Sys.Date()`
```{r start,include=FALSE}
# file settings
knitr::opts_chunk$set(include=TRUE,echo=TRUE)
```

#### Setup
```{r setup 1,message=FALSE,warning=FALSE}
# loads data and libraries
setwd("C:/Users/dwexler/Desktop/R/nps-repo/rf")
x <- read.csv("rf_data.csv")
y <- read.csv("rf_labels.csv")
suppressWarnings({library(randomForest)})
suppressWarnings({library(knitr)})
suppressWarnings({library(ggplot2)})
suppressWarnings({library(tidyr)})
```

```{r setup 2}
# EDIT 'variables' TO CHANGE WHAT PREDICTORS ARE USED IN MODEL
variables <- c("durMn","durSd","idxMagMn","idxMagSd","tcbMagMn","tcbMagSd",
               "tcgMagMn","tcgMagSd","tcwMagMn","tcwMagSd","tcbPreMn",
               "tcbPreSd","tcgPreMn","tcgPreSd","tcwPreMn","tcwPreSd",
               "tcbPstMn","tcbPstSd","tcgPstMn","tcgPstSd","tcwPstMn",
               "tcwPstSd","area","perim","shape_1","tcbPst01Mn","tcbPst01Sd",
               "tcbPst03Mn","tcbPst03Sd","tcbPst07Mn","tcbPst07Sd",
               "tcbPst15Mn","tcbPst15Sd","tcgPst01Mn","tcgPst01Sd",
               "tcgPst03Mn","tcgPst03Sd","tcgPst07Mn","tcgPst07Sd",
               "tcgPst15Mn","tcgPst15Sd","tcwPst01Mn","tcwPst01Sd",
               "tcwPst03Mn","tcwPst03Sd","tcwPst07Mn","tcwPst07Sd",
               "tcwPst15Mn","tcwPst15Sd")
###############################################################################
# list of disturbance types used to filter data
disturbances <- c("Avalanche","Inter-annual Variability","Clearing",
                  "Mass Movement","Progressive Defoliation","Riparian",
                  "Fire","Post Fire Defoliation","Tree Toppling",
                  "Development","Post Clearing","Post Tree Toppling","Water")
# list of shortened disturbance labels for plotting
dist_labels <- c("Avalanche","IntAnnVar","Clearing","MassMov","ProgDef",
                 "Riparian","Fire","PostFireDef","TreeTopp","Devel",
                 "PostClear","PostTreeTopp","Water")
```

#### Filtering and Cleaning Data
```{r filtering}
# EDIT 'elevation_mask' TO INCLUDE OR EXCLUDE PATCHES IN ELEVATION MASK
elevation_mask <- FALSE
# EDIT 'show_yearly_breakdown' TO HIDE OR SHOW YEARLY DISTURBANCE BREAKDOWN
show_yearly_breakdown <- FALSE
# EDIT 'group' TO GROUP OR NOT GROUP 'POST' EVENTS WITH THEIR PARENT CLASSES
group_post_classes <- TRUE
# EDIT 'disturbances' TO CHANGE DISTURBANCES INCLUDED IN MODEL
dist_subset <- c(1,2,3,4,5,6,7,9)
###############################################################################
# removes patches without a labeled change type
x <- x[y$ChangeType!="",]
y <- y[y$ChangeType!="",]
# gets the disturbance years and elevation mask binaries
years <- data.frame(x[,c("yod")])
year_list <- unique(years)[,1]
mask <- data.frame(y[,c("ChangeDesc")])
# filters by variable and converts data to numeric
x <- data.frame(sapply(x[,variables],as.numeric))
y <- data.frame(y[c("ChangeType")])
# filters out data in elevation mask
if (elevation_mask) {
  years <- years[mask[,1]!="Fully in mask",,drop=FALSE]
  x <- x[mask[,1]!="Fully in mask",]
  y <- y[mask[,1]!="Fully in mask",,drop=FALSE]
}
# displays frequency distribution of disturbances
kable(table(y),align="l",caption="Distribution of disturbances")
# displays breakdown of disturbances by year
if (show_yearly_breakdown) {
  kable(table(years[,1],y[,1]),align="l",caption="Yearly disturbances")
}
# groups 'post' events with their parent classes
if (group_post_classes) {
  y[y[,1]=="Post Fire Defoliation",] <- "Fire"
  y[y[,1]=="Post Tree Toppling",] <- "Tree Toppling"
  y[y[,1]=="Post Clearing",] <- "Clearing"
}
# filters data by disturbance type
disturbances <- disturbances[dist_subset]
labels_subset <- dist_labels[dist_subset]
dists <- length(disturbances)
x <- x[y[,1]%in%disturbances,]
y <- y[y[,1]%in%disturbances,,drop=FALSE]
```

#### Train-Test Split
```{r split}
# EDIT 'split' TO CHANGE THE TRAINING SPLIT
split <- 0.75
###############################################################################
# creates a training and testing set
x_train <- data.frame(matrix(0,0,ncol(x)))
y_train <- data.frame(matrix("",0,1))
x_test <- data.frame(matrix(0,0,ncol(x)))
y_test <- data.frame(matrix("",0,1))
# creates a subset of each disturbance type
for (disturbance in disturbances) {
  x_subset <- x[y[,1]==disturbance,]
  y_subset <- y[y[,1]==disturbance,,drop=FALSE]
  num_rows <- nrow(x_subset)
  index_subset <- sample.int(num_rows,num_rows*split)
  x_train <- rbind(x_train,x_subset[index_subset,])
  y_train <- rbind(y_train,y_subset[index_subset,,drop=FALSE])
  x_test <- rbind(x_test,x_subset[-index_subset,])
  y_test <- rbind(y_test,y_subset[-index_subset,,drop=FALSE])
}
# converts labels to factor data type
y_train <- factor(sapply(y_train,as.factor))
y_test <- factor(sapply(y_test,as.factor))
```

#### Random Forest Training
```{r training}
# EDIT 'reps' TO CHANGE THE NUMBER OF TREES IN EACH RANDOM FOREST
reps <- 50
# EDIT 'percentages' TO CHANGE PERCENTILE CUTOFFS FOR VARIABLES
percentages <- seq(0,0.9,0.1)
###############################################################################
# constructs vector to balance the training data
sample <- replace(table(y_train),table(y_train)>100,100)
# runs random forest and extracts most important variables
forest <- randomForest(x=x_train,y=y_train,importance=TRUE,
                       ntree=reps,sampsize=sample,strata=y_train)
gini <- forest$importance[,"MeanDecreaseGini"]
# runs random forest using different combinations of variables
results <- data.frame(matrix(0,length(percentages),7))
colnames(results) <- c("numPredictors","oobError","avgClassError","maxError",
                       "1stPredictor","2ndPredictor","3rdPredictor")
predictions <- data.frame(matrix(0,length(percentages),dists))
colnames(predictions) <- sort(disturbances)
min_class_error <- 99999
best_variables <- NULL
for (i in 1:length(percentages)) {
  x_subset <- x_train[,gini>quantile(gini,probs=percentages[i])]
  forest_subset <- randomForest(x=x_subset,y=y_train,importance=TRUE,
                                ntree=reps,sampsize=sample,strata=y_train)
  # stores number of predictors
  results[i,1] <- ncol(x_subset)
  # stores out of bound error rate
  results[i,2] <- round(forest_subset$err.rate[reps,"OOB"]*100,2)
  avg_class_error <- round(mean(forest_subset$confusion[,"class.error"])*100,2)
  # stores predictors used during the run with the lowest average class error
  results[i,3] <- avg_class_error
  if (avg_class_error < min_class_error) {
    min_class_error <- avg_class_error
    best_variables <- colnames(x_subset)
  }
  # stores the maximum class error
  results[i,4] <- round(max(forest_subset$confusion[,"class.error"])*100,2)
  # stores the top three predictors
  gini_subset <- data.frame(forest_subset$importance[,"MeanDecreaseGini"])
  sorted_gini <- rownames(gini_subset)[order(gini_subset[,1],decreasing=TRUE)]
  results[i,c(5,6,7)] <- sorted_gini[c(1,2,3)]
  # stores the disturbance specific class errors
  predictions[i,] <- round(forest_subset$confusion[,"class.error"]*100,2)
}
# displays results
sample_print <- as.data.frame(sample)
colnames(sample_print) <- c("ChangeType","Freq")
kable(sample_print,align="l",caption="Frequency distribution of disturbances used to train model")
kable(results,align="l",row.names=TRUE,caption="Error rates and top predictors from all runs")
kable(predictions,align="l",row.names=TRUE,caption="Disturbance specific errors from all runs")
```

#### Random Forest Testing
```{r testing}
# runs random forest with most predictive variables and displays results
x_train_subset <- x_train[,best_variables]
x_test_subset <- x_test[,best_variables]
best_forest <- randomForest(x=x_train_subset,y=y_train,xtest=x_test_subset,
                            ytest=y_test,importance=TRUE,ntree=reps,
                            sampsize=sample,strata=y_train)
# calculates statistics for random forest run
confusion_train <- best_forest$confusion
confusion_train[,"class.error"] <- round(confusion_train[,"class.error"]*100,2)
colnames(confusion_train)[length(colnames(confusion_train))] <- "Error"
oob_error <- round(best_forest$err.rate[reps,"OOB"]*100,2)
class_error_train <- round(mean(best_forest$confusion[,"class.error"])*100,2)
confusion_test <- best_forest$test$confusion
confusion_test[,"class.error"] <- round(confusion_test[,"class.error"]*100,2)
colnames(confusion_test)[length(colnames(confusion_test))] <- "Error"
class_error_test <- round(mean(best_forest$test$confusion[,"class.error"])*100,2)
avalanche_test <- confusion_test["Avalanche","Error"]
toppling_test <- confusion_test["Tree Toppling","Error"]
# displays results
kable(confusion_train,align="l",caption=paste
      ("Confusion matrix for best training run with ",
        ncol(x_train_subset)," variables (avg class error: ",
        class_error_train,", oob_error: ",oob_error,")",sep=""))
kable(confusion_test,align="l",caption=paste
      ("Confusion matrix for test set with ",ncol(x_train_subset),
        " variables (avg class error: ",class_error_test,")",sep=""))
```

#### Plotting Test Results
```{r plotting 1,warning=FALSE,fig.align='center'}
# gets the percent of trees that voted for each correct classification
y_test <- factor(sapply(y_test,as.factor))
votes <- best_forest$test$votes
vote_percents <- data.frame()
for (i in 1:nrow(votes)) {
  row <- votes[i,]
  label <- colnames(votes)[which.max(row)]
  if (label==y_test[i]) {
    row_num <- nrow(vote_percents)+1
    vote_percents[row_num,1] <- max(row)
    vote_percents[row_num,2] <- label
  }
}
# divides these winning classifications into bins based on confidence
thresholds_graph <- data.frame(matrix(0,5,dists+1))
thresholds_graph[,dists+1] <- c("80-100%","60-80%","40-60%","20-40%","0-20%")
for (i in 1:dists) {
  vote_subset <- vote_percents[vote_percents[,2]==disturbances[i],1]
  den <- length(vote_subset)
  thresholds_graph[1,i] <- (length(vote_subset[(vote_subset>=.8&vote_subset<=1)])/den)*100
  thresholds_graph[2,i] <- (length(vote_subset[(vote_subset>=.6&vote_subset<.8)])/den)*100
  thresholds_graph[3,i] <- (length(vote_subset[(vote_subset>=.4&vote_subset<.6)])/den)*100
  thresholds_graph[4,i] <- (length(vote_subset[(vote_subset>=.2&vote_subset<.4)])/den)*100
  thresholds_graph[5,i] <- (length(vote_subset[(vote_subset>=0&vote_subset<.2)])/den)*100
}
# plots the results
colnames(thresholds_graph) <- append(labels_subset,"Confidence")
thresholds_graph <- pivot_longer(data=thresholds_graph,cols=all_of(labels_subset),
                                 names_to="Disturbance",values_to="Percent")
ggplot(data=thresholds_graph,aes(x=Disturbance,y=Percent,fill=Confidence))+
  geom_bar(stat="identity",color="black",width=0.9,position=position_stack(reverse=TRUE))+
  labs(y="% of Disturbances",title="RF Correct Classification Confidence Levels")+
  guides(fill=guide_legend(reverse=TRUE))+theme(plot.title=element_text(hjust=0.5))
```

```{r plotting 2,fig.align='center'}
# gets the classification error of each class with a confidence threshold
y_test <- as.data.frame(y_test)
thresholds <- c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)
threshold_data <- data.frame(matrix(0,length(thresholds),dists))
# loops through the thresholds
for (i in 1:length(thresholds)) {
  threshold <- thresholds[i]
  # loops through the disturbance types
  for (j in 1:dists) {
    vote_subset <- votes[y_test==disturbances[j],]
    predicted_subset <- best_forest$test$predicted[y_test==disturbances[j]]
    y_test_subset <- y_test[y_test==disturbances[j],,drop=FALSE]
    num <- 0
    den <- 0
    # finds the percent of a disturbance type correctly classified with a
    # confidence above the current threshold
    for (k in 1:nrow(vote_subset)) {
      if (max(vote_subset[k,]) >= threshold) {
        den <- den+1
        if (predicted_subset[k]==y_test_subset[k,1]) {
          num <- num+1
        }
      }
    }
    threshold_data[i,j] <- round((1-(num/den))*100,2)
  }
}
# plots the results
thresholded_avg <- rowSums(threshold_data, na.rm=T)/dists
thresholded_graph <- data.frame(Confidence=thresholds*100,Error=thresholded_avg)
colnames(threshold_data) <- labels_subset
threshold_percents <- c("0%","10%","20%","30%","40%","50%","60%","70%","80%","90%")
threshold_chart <- cbind(data.frame(Confidence=threshold_percents),threshold_data)
kable(threshold_chart,align="l",
      caption="RF disturbance classification error by confidence")
ggplot(data=thresholded_graph,aes(x=Confidence,y=Error,group=1))+geom_line(color="red")+
  labs(x="Threshold (%)",y="Average Class Error (%)",title="RF Classification Error")+
  geom_point()+theme(plot.title=element_text(hjust=0.5))+xlim(0,100)
```

#### Training New Forest
```{r retraining 1}
# subsets data to only include avalanche and tree toppling events
dists_v2 <- c("Avalanche","Tree Toppling")
y_train <- as.data.frame(y_train)
y_test <- as.data.frame(y_test)
x_train_v2 <- x_train[y_train[,1]%in%dists_v2,]
y_train_v2 <- y_train[y_train[,1]%in%dists_v2,,drop=FALSE]
x_test_v2 <- x_test[y_test[,1]%in%dists_v2,]
y_test_v2 <- y_test[y_test[,1]%in%dists_v2,,drop=FALSE]
y_train <- factor(sapply(y_train,as.factor))
y_test <- factor(sapply(y_test,as.factor))
y_train_v2 <- factor(sapply(y_train_v2,as.factor))
y_test_v2 <- factor(sapply(y_test_v2,as.factor))
```

```{r retraining 2}
# runs random forest and extracts most important variables
forest <- randomForest(x=x_train_v2,y=y_train_v2,importance=TRUE,
                       ntree=reps,sampsize=table(y_train_v2),strata=y_train_v2)
gini <- forest$importance[,"MeanDecreaseGini"]
# runs random forest using different combinations of variables
min_class_error <- 99999
best_variables <- NULL
for (i in 1:length(percentages)) {
  x_subset <- x_train_v2[,gini>quantile(gini,probs=percentages[i])]
  forest_subset <- randomForest(x=x_subset,y=y_train_v2,importance=TRUE,ntree=reps,
                                sampsize=table(y_train_v2),strata=y_train_v2)
  # stores predictor variables used during the lowest error run
  if (avg_class_error < min_class_error) {
    min_class_error <- avg_class_error
    best_variables <- colnames(x_subset)
  }
}
```

```{r retraining 3}
# runs random forest with most predictive variables and displays results
x_train_subset_v2 <- x_train_v2[,best_variables]
x_test_subset_v2 <- x_test_v2[,best_variables]
best_forest_v2 <- randomForest(x=x_train_subset_v2,y=y_train_v2,xtest=x_test_subset_v2,
                            ytest=y_test_v2,importance=TRUE,ntree=reps,
                            sampsize=table(y_train_v2),strata=y_train_v2)
# calculates statistics for random forest run
confusion_train <- best_forest_v2$confusion
confusion_train[,"class.error"] <- round(confusion_train[,"class.error"]*100,2)
colnames(confusion_train)[length(colnames(confusion_train))] <- "Error"
oob_error <- round(best_forest_v2$err.rate[reps,"OOB"]*100,2)
class_error_train <- round(mean(best_forest_v2$confusion[,"class.error"])*100,2)
confusion_test <- best_forest_v2$test$confusion
confusion_test[,"class.error"] <- round(confusion_test[,"class.error"]*100,2)
colnames(confusion_test)[length(colnames(confusion_test))] <- "Error"
class_error_test <- round(mean(best_forest_v2$test$confusion[,"class.error"])*100,2)
# displays results
kable(confusion_train,align="l",caption=paste
      ("Confusion matrix for best training run with ",
        ncol(x_train_subset_v2)," variables (avg class error: ",
        class_error_train,", oob_error: ",oob_error,")",sep=""))
kable(confusion_test,align="l",caption=paste
      ("Confusion matrix for test set with ",ncol(x_train_subset_v2),
        " variables (avg class error: ",class_error_test,")",sep=""))
avalanche_test_v2 <- confusion_test["Avalanche","Error"]
toppling_test_v2 <- confusion_test["Tree Toppling","Error"]
v2_results <- data.frame(Avalanche=c(avalanche_test,avalanche_test_v2),
                         TreeTopp=c(toppling_test,toppling_test_v2))
rownames(v2_results) <- c("Initial Testing Error","Retrained Testing Error")
kable(v2_results,align="l",caption="Initial and retrained testing errors")
```

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>
