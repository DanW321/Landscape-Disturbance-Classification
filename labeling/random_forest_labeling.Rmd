---
title: "Random Forest Labeling"
output:
  html_document:
    theme: default
    highlight: pygments
    toc: true
    toc_depth: 3
    toc_float: true
editor_options:
  chunk_output_type: console
---
Author: Dan Wexler\
Date: `r Sys.Date()`

This script walks through the process of using an already trained random
forest model for labeling natural disturbance patches. It is divided into
sections that delineate different parts of the process, such as cleaning the
input data, applying the model, and summarizing the results. Below are the
inputs to and outputs of this script.\
INPUTS:\
1) .csv file generated by Google Earth Engine where each row represents a
disturbance polygon and each column is the value of a certain predictor
variable for that polygon.\
2) Trained random forest model that can be used to predict disturbance
labels for polygons.\
3) Table breaking down probability thresholds and omission rates for each
disturbance in the random forest model.\
4) List of variables used in the final random forest model.\
OUTPUTS:\
1) A table containing the unique ids for each disturbance patch, the label
generated by the random forest model, the probability assigned by the model
of that label being a certain disturbance class, and a flag indicating whether
that label should be accepted or rejected, based on the probability.

### (1) Setup
This block of code contains variables that the user can modify to fit their
specific needs. This is the only block of code that requires user input,
barring more involved modification of the script. The in-line comments detail
specifically what each variable represents.
```{r setup 1}
# the path to the file containing the predictor variables
predictors_path <- "C:/Users/dwexler/Desktop/R/nps-repo/training/predictors.csv"
# the path to the file containing the random forest model, should also contain
# a probability table broken down by disturbance and a list of variables
model_path <- "C:/Users/dwexler/Desktop/R/nps-repo/training/best_random_forest"
# the name of the file that will store labels generated by the model
save_name <- "disturbance_labels"
```

Here we load the R libraries that are used throughout the script. Some or all 
of them may have to be downloaded.
```{r setup 2,message=FALSE,warning=FALSE}
# loads R libraries
library(randomForest)
library(DT)
library(dplyr)
```

Now we load and clean the four inputs to this script. These inputs include
a list of variables used in the random forest model, an array of predictor
variables for each disturbance patch, the trained random forest model, and a
table with probability and error metrics for each disturbance type.
```{r setup 3}
# loads the list of variables that the model will use to make classifications
variables <- read.csv(paste(model_path,"_variables.csv",sep=""))[,1]
# loads the predictor variables
predictors <- read.csv(predictors_path)
# extracts a list of unique patch ids
ids <- data.frame(predictors$patch_name)
# filters the predictor variables using the loaded list of variables
predictors <- subset(predictors,select=variables)
# converts the variables to numeric and changes NA values to 0
predictors <- data.frame(sapply(predictors,as.numeric))
predictors[is.na(predictors)] <- 0
# loads the trained random forest model
forest <- readRDS(model_path)
# loads the table containing probability and error metrics for each disturbance
metrics <- read.csv(paste(model_path,"_metrics.csv",sep=""))
disturbances <- metrics[,1]
metrics <- metrics[,c(2,3)]
rownames(metrics) <- disturbances
```

### (2) Labeling
We are now ready to apply the random forest model to label disturbance patches.
This block of code feeds the predictor variables through the model, then
analyzes the voting results to determine whether a particular label is
'acceptable' given the probability thresholds found in the training script.
The result is a table containing the unique ids for each disturbance patch, the 
label generated by the random forest model, the probability assigned by the 
model of that label being a certain disturbance class, and a flag indicating 
whether that label should be accepted or rejected, based on the probability.
The first 10 rows of the output are shown as an example.
```{r labeling}
# applied the random forest model
predictions <- as.data.frame(predict(forest,predictors,type="prob"))
# create a data frame to store results
results <- data.frame(matrix(NA,nrow(predictions),5))
results[,1] <- ids
colnames(results) <- c("ID","Label","Probability","Threshold","Acceptable")
# for each disturbance patch
for (i in 1:nrow(predictions)) {
  # find the index of the most likely label
  max_ind <- which(predictions[i,]==max(predictions[i,]))
  # if there was a voting tie
  if (length(max_ind)>1) {
    # randomly pick between the tied options
    max_ind <- sample(max_ind,1)
  }
  # find the name of the most likely label 
  label <- colnames(predictions)[max_ind]
  # find the probability that the patch is that disturbance type
  prob <- round(predictions[i,max_ind]*100,2)
  # find the probability threshold for the disturbance type
  threshold <- metrics[label,1]
  # if the modeled probability is greater than the threshold, change the
  # 'acceptable' flag to yes, otherwise no
  acceptable <- "no"
  if (!is.na(threshold)) {
    if (prob>=threshold) {
      acceptable <- "yes"
    }
  }
  # store the results
  results[i,2] <- label
  results[i,3] <- prob
  results[i,4] <- threshold
  results[i,5] <- acceptable
}
# displays the first 10 results as an example
DT::datatable(results[1:10,],class="cell-border stripe hover",
              caption="Disturbance labels head",rownames=FALSE,
              options=list(pageLength=15,dom="t",order=list(classes="no-sort")))
```

### (3) Saving Results
This section saves the labeled disturbance patches (along with probability and
acceptance information). This file will save to the folder in which the script
is located. It can also be downloaded using the 'CSV' button above.
```{r saving results}
# saves the labeled disturbance patches
write.csv(results,file=paste(save_name,".csv",sep=""),row.names=FALSE)
```

### (4) Analysis
This section walks through some light analyses of the labeling results. We look
at the distribution of labels, how many labels were accepted, the
disturbance-wise classification probabilities, and more.
```{r analysis 1}
# gets the total number of disturbance patches
total <- nrow(predictions)
# gets a distribution of labels
distribution <- table(results$Label)
# filters the labeling results by acceptance
results_accepted <- results[results$Acceptable=="yes",]
# gets the number of accepted results
accepted <- nrow(results_accepted)
# creates a data frame to store analysis information
analysis <- data.frame(matrix(NA,length(disturbances),3))
rownames(analysis) <- disturbances
colnames(analysis) <- c("Num Labeled","Percent Accepted (%)","Avg Probability (%)")
# for each disturbance
for (i in 1:length(disturbances)) {
  # get the current disturbance
  disturbance <- disturbances[i]
  # filter the labeling results by the current disturbance type
  results_filtered <- results_accepted[results_accepted$Label==disturbance,]
  # if any patches where classified as this disturbance type
  if (nrow(results_filtered)!=0) {
    # store the number of classifications
    analysis[i,1] <- nrow(results_filtered)
    # store the percent of accepted classifications
    analysis[i,2] <- round(nrow(results_filtered)/distribution[disturbance]*100,2)
    # store the average probability at which classifications were made
    analysis[i,3] <- round(mean(results_filtered$Probability),2)
  }
}
# calculate the total acceptance rate across all disturbances
percent_accepeted <- round((accepted/total)*100,2)
# display a table showing analysis results
caption <- paste("Labeling breakdown (total percent accepted: ",percent_accepeted,"%)",sep="")
DT::datatable(analysis,class="cell-border stripe hover",
              caption=caption,extensions='Buttons',
              options=list(pageLength=nrow(analysis),dom="Bt",
                           order=list(classes="no-sort"),
                           buttons=list(list(extend="csv",title="labeling_breakdown"))))
```

```{r analysis 2}
labels <- read.csv("C:/Users/dwexler/Desktop/R/nps-repo/training/labels.csv")
spl <- strsplit(ids[,1],"_")[[1]]
labels <- mutate(labels,patch_name=paste(spl[1],spl[2],spl[3],spl[4],spl[5],yod,annualID,sep='_'))
results_sort <- arrange(results,ID)
labels_sort <- arrange(labels,patch_name)
results_sort <- results_sort[labels_sort$ChangeType!="",]
labels_sort <- labels_sort[labels_sort$ChangeType!="",]
errors <- data.frame(matrix(0,length(disturbances),1))
rownames(errors) <- disturbances
colnames(errors) <- c("Error")
for (i in 1:length(disturbances)) {
  disturbance <- disturbances[i]
  results_filt <- results_sort[labels_sort$ChangeType==disturbance,]
  labels_filt <- labels_sort[labels_sort$ChangeType==disturbance,]
  num <- 0
  dem <- nrow(labels_filt)
  for (j in 1:nrow(labels_filt)) {
    if (results_filt$Label[j]==labels_filt$ChangeType[j]) {
      num <- num+1
    }
  }
  errors[i,1] <- round((1-(num/dem))*100,2)
}
DT::datatable(errors,class="cell-border stripe hover",
              caption="Classification Errors",extensions='Buttons',
              options=list(pageLength=nrow(errors),dom="Bt",
                           order=list(classes="no-sort"),
                           buttons=list(list(extend="csv",title="classification_errors"))))
```

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>
