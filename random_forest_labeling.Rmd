---
title: "Random Forest Labeling"
output:
  html_document:
    theme: default
    highlight: pygments
    toc: true
    toc_depth: 3
    toc_float: true
editor_options:
  chunk_output_type: console
---
Author: Dan Wexler\
Date: `r Sys.Date()`

This script walks through the process of using an already trained random
forest model for labeling natural disturbance patches. It is divided into
sections that delineate different parts of the process, such as cleaning the
input data, applying the model, and summarizing the results. Below are the
inputs to and outputs of this script.\
INPUTS:\
1) .csv file generated by Google Earth Engine where each row represents a
disturbance polygon and each column is the value of a certain predictor
variable for that polygon.\
2) Trained random forest model that can be used to predict disturbance
labels for polygons.\
3) Table breaking down probability thresholds and omission rates for each
disturbance in the random forest model.\
4) List of variables used in the final random forest model.\
OUTPUTS:\
1) A table containing the unique ids for each disturbance patch, the label
generated by the random forest model, the probability assigned by the model
of that label being a certain disturbance class, and a flag indicating whether
that label should be accepted or rejected, based on the probability.

### (1) Setup
This block of code contains variables that the user can modify to fit their
specific needs. This is the only block of code that requires user input,
barring more involved modification of the script. The in-line comments detail
specifically what each variable represents.
```{r setup 1}
# the path to the folder containing this project
folder <- "C:/Users/dwexler/Desktop/R/Landscape-Disturbance-Classification/"
# the name of the file containing the predictor variables
predictors_file <- "predictors.csv"
# the name of the file that will store labels generated by the model
save_name <- "disturbance_labels.csv"
# if TRUE, filter out disturbance patches from the year 1987
drop_1987 <- TRUE
# the number of each disturbance type to be flagged for QA/QC sampling
sample_size <- 50
```

This block of code contains a function for creating tables that will be used
throughout the script.
```{r setup 2}
# function for creating tables
create_table <- function(table,title,rows) {
  DT::datatable(table,class="cell-border stripe hover",
                rownames=rows,caption=title,
                options=list(pageLength=nrow(table),dom="t",
                             order=list(classes="no-sort")))
}
```

Here we load the R libraries that are used throughout the script. Some or all 
of them may have to be downloaded.
```{r setup 3,message=FALSE,warning=FALSE}
# loads R libraries
library(randomForest)
library(DT)
library(dplyr)
```

Now we load and clean the four inputs to this script. These inputs include
a list of variables used in the random forest model, an array of predictor
variables for each disturbance patch, the trained random forest model, and a
table with probability and error metrics for each disturbance type.
```{r setup 4}
# sets the path from which files will be loaded
intermediate <- paste(folder,"intermediate/","best_random_forest",sep="")
# loads the list of variables that the model will use to make classifications
variables <- read.csv(paste(intermediate,"_variables.csv",sep=""))[,1]
# loads the predictor variables
predictors <- read.csv(paste(folder,"input/",predictors_file,sep=""))
# filters out patches from the year 1987
if (drop_1987) {
  predictors <- predictors[predictors$yod!=1987,]
}
# extracts a list of unique patch ids
ids <- data.frame(predictors$patch_name)
# filters the predictor variables using the loaded list of variables
predictors <- subset(predictors,select=variables)
# converts the variables to numeric and changes NA values to 0
predictors <- data.frame(sapply(predictors,as.numeric))
predictors[is.na(predictors)] <- 0
# loads the trained random forest model
forest <- readRDS(paste(intermediate,".RData",sep=""))
# loads the table containing probability and error metrics for each disturbance
metrics <- read.csv(paste(intermediate,"_metrics.csv",sep=""))
disturbances <- metrics[,1]
metrics <- metrics[,c(2,3,4)]
rownames(metrics) <- disturbances
```

### (2) Labeling
We are now ready to apply the random forest model to label disturbance patches.
This block of code feeds the predictor variables through the model, then
analyzes the voting results to determine whether a particular label is
'acceptable'. This acceptability is determine by three criteria. The first is
whether classifications of a certain disturbance type are significant, as
determined by the training script. The second is whether the probability at 
which a classification was made is greater than the probability threshold 
determined in the training script. The third is if the classification 
probability is greater than 1/k, k being the number of disturbance classes.
This represents a "majority" vote. The result is a table containing the unique
ids for each disturbance patch, the best label generated by the random forest
model, the probability of that classification, and a flag indicating whether
that label should be accepted or rejected. The label, probability, and
acceptance are also displayed for the second best classification. The last
column displays the final classification, based on the first and second best
classifications and their respective acceptances. If the first label is not
acceptable, but the second is, the second label is assigned. If neither the
first nor second label is acceptable, no label is assigned. The first 10 rows 
of the output are shown as an example, with the patch IDs hidden for display.\
\
This code defines a function that checks if a classification is acceptable...
```{r labeling 1}
# a function that checks if a certain classification is acceptable
check_threshold <- function(votes,ind) {
  # gets the disturbance label
  label <- votes[ind,1]
  # gets the probability of classification
  prob <- votes[ind,2]*100
  # gets the probability threshold for the disturbance type
  threshold <- metrics[label,1]
  # finds whether classifications of this disturbance type are significant
  sig <- metrics[label,3]
  # if the probability of classification is greater than the threshold, if
  # classifications of this disturbance type are significant, and if the
  # probability is greater than 1/k where k is the number of disturbances,
  # change the 'accept' flag to 'yes', otherwise 'no'
  accept <- "no"
  if (!is.na(threshold)) {
    if (prob>=threshold & sig=="yes" & prob>=100/length(disturbances)) {
      accept <- "yes"
    } 
  }
  # return the accept flag
  return (accept)
}
```

...and this code uses the function to label the disturbance patches.
```{r labeling 2}
# applies the random forest model and gets voting distributions
predictions <- as.data.frame(predict(forest,predictors,type="prob"))
# creates a data frame to store results
results <- data.frame(matrix(NA,nrow(predictions),7))
results[,1] <- ids
colnames(results) <- c("ID","Label1","Prob1","Accept1","Label2","Prob2","Accept2")
# for each disturbance patch
for (i in 1:nrow(predictions)) {
  # get the voting distribution
  to_sort <- data.frame(Label=disturbances,Errors=as.numeric(predictions[i,]))
  # sort the voting distribution
  sorted <- to_sort[order(to_sort$Errors,decreasing=TRUE),]
  # gets the the disturbance(s) with the highest probabilities
  best_ind <- which(sorted[,2]==max(sorted[,2]))
  next_ind <- 2
  # if there is a tie for most likely disturbance 
  if (length(best_ind)>1) {
    # randomly select between the tied disturbances
    pick <- sample(best_ind,2,replace=FALSE)
    best_ind <- pick[1]
    next_ind <- pick[2]
  }
  # store the results
  results[i,2] <- sorted[best_ind,1]
  results[i,3] <- round(sorted[best_ind,2]*100,2)
  results[i,4] <- check_threshold(sorted,best_ind)
  results[i,5] <- sorted[next_ind,1]
  results[i,6] <- round(sorted[next_ind,2]*100,2)
  results[i,7] <- check_threshold(sorted,next_ind)
}
# displays the labeling results
caption <- "First 10 rows of labeling results (patch IDs are hidden)"
create_table(results[1:10,2:7],caption,FALSE)
```

This block adds a new column to the label array shown above containing a flag
that indicates whether that particular disturbance patch will be a part of the
QAQC process. 50 of each disturbance type are randomly chosen for QAQC. If
there are fewer than 50 of a certain type of disturbance, all of the patches
of that disturbance type are flagged for QAQC.
```{r labeling 3}
# adds a new column for QAQC flags to result array
results$QAQC <- FALSE
# for each disturbance
for (i in 1:length(disturbances)) {
  dist <- disturbances[i]
  # filter the results array by disturbance type
  indices <- which(results$Label1==dist&results$Accept1=="yes")
  # find the number of accepted disturbances
  num_dists <- length(indices)
  # if there are any disturbances of the current type
  if (num_dists>0) {
    samp <- 0
    # if there are fewer than a critical number of disturbances
    if (num_dists < sample_size) {
      # set the sample size equal to the number of disturbances
      samp <- num_dists
    # if there are more than a critical number of disturbances
    } else {
      # set the sample size equal to the user chosen value
      samp <- sample_size
    }
    # flag a random selection of the current disturbance type for QAQC
    rand_indices <- sample(indices,samp,replace=FALSE)
    results[rand_indices,"QAQC"] <- TRUE
  }
}
```

### (3) Saving Results
This section saves the labeled disturbance patches (along with probability and
acceptance information). This file will save to the folder in which the script
is located.
```{r saving results}
# saves the labeled disturbance patches
write.csv(results,file=paste(folder,"output/",save_name,sep=""),row.names=FALSE)
```

### (4) Analysis
This section walks through some light analyses of the labeling results. We look
at the distribution of accepted labels, the disturbance-wise classification
probabilities, and more.
```{r analysis 1}
# creates a data frame to store results
analysis <- data.frame(matrix(NA,length(disturbances),6))
analysis[,1] <- disturbances
colnames(analysis) <- c("Disturbance","Total","Accepted","% Accepted",
                        "Avg Accepted Prob","Secondary")
# for each disturbance
for (i in 1:length(disturbances)) {
  # get the current disturbance
  dist <- disturbances[i]
  # filter the labels by the current disturbance type
  total <- results[results$Label1==dist,]
  # filter the labels by accepted disturbance labels
  accpt <- results[which(results$Label1==dist&results$Accept1=="yes"),]
  # filter the labels by accepted secondary disturbance labels
  secnd <- results[which(results$Label2==dist&results$Accept2=="yes"&results$Accept1=="no"),]
  # store the results
  analysis[i,2] <- nrow(total)
  analysis[i,3] <- nrow(accpt)
  analysis[i,4] <- round((nrow(accpt)/nrow(total))*100,2)
  analysis[i,5] <- round(mean(accpt$Prob1),2)
  analysis[i,6] <- nrow(secnd)
}
# finds the percent contribution of primary and secondary labels
best_accepted <- round((sum(analysis[,3],na.rm=TRUE)/nrow(results))*100,2)
next_accepted <- round((sum(analysis[,6],na.rm=TRUE)/nrow(results))*100,2)
totl_accepted <- best_accepted+next_accepted
```

The following table displays the distribution of the accepted primary labels.
For each disturbance, the number of patches that received that label is shown, 
as well as the average classification probabilities and acceptance rate. The 
final column shows the number of accepted secondary labels.\
------------------------------------------------------------------------------\
The percent contribution of primary labels is: `r best_accepted`%\
The percent contribution of secondary labels is: `r next_accepted`%\
The total percent of disturbances labeled is: `r totl_accepted`%\
------------------------------------------------------------------------------\
```{r analysis 2}
# displays the table described above
create_table(analysis,"Label breakdown",FALSE)
```

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>
